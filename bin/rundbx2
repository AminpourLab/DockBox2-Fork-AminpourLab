#!/usr/bin/env python
import os
import sys
import argparse
import time
import random
import numpy as np

os.environ['TF_CPP_MIN_LOG_LEVEL'] = str(2)
os.environ['PYTHONHASHSEED'] = str(2)

from dockbox2.datasets import *
from dockbox2 import dbxconfig

from dockbox2 import models
from dockbox2.utils import *

import tensorflow as tf

# command-line arguments and options
parser = argparse.ArgumentParser(description="Run DBX2 GNN model")

parser.add_argument('-f',
    dest='config_file',
    required=True,
    metavar='FILE',
    help='config file containing model parameters')

parser.add_argument('-t',
    type=str,
    dest='pickfile',
    metavar='FILE',
    required=True,
    help='pickle file containing graphs of poses')

parser.add_argument('-w',
    dest='h5file',
    required=True,
    metavar='FILE',
    help='h5 file containing trained weights')

parser.add_argument('-o',
    dest='output_file',
    required=False,
    metavar='FILE',
    default='dbx2.score',
    help='File containing with dbx2 scores are listed')

parser.add_argument('--seed',
    dest='seed',
    default=None,
    metavar='INT',
    type=int,
    help='Random seed')

parser.add_argument('--task',
    dest='task_level',
    default='node',
    choices=['node', 'graph'],
    required=False,
    help="task-level prediction: node (pose correctness) or graph (pKd values)")

# update parsers with arguments
args = parser.parse_args()

# check task level
task_level = list(dict.fromkeys(args.task_level))
task_level = sorted(task_level, reverse=True)

if all(task not in task_level for task in ['node', 'graph']):
    raise ValueError("Task level should be node and/or graph")

if args.seed is not None:
    seed = args.seed
else:
    seed = random.randint(0, 1e10)
    print("random seed is set to %i"%seed)
set_seed(args.seed)

config = dbxconfig.ConfigSetup(args.config_file)

depth = config.depth
classifier = config.classifier
nrof_neigh = config.nrof_neigh
use_edger = config.use_edger

dataset = GraphDataset(args.pickfile, config.node, config.edger, task_level, training=False)
data_loader, data_slices = generate_data_loader(dataset, depth, nrof_neigh, **config.minibatch, randomize=True)

model = models.GraphSAGE(dataset.nfeats, dataset.nlabels, depth, nrof_neigh, use_edger, config.loss, config.aggregator, \
    config.classifier, config.readout, config.node, attention_options=config.gat, edger_options=config.edger, task_level=args.task_level)
model.build()

model.load_weights_h5(args.h5file)
labels, pred_labels, best_node_labels, pred_best_node_labels, is_correct_labels, graph_size = (None, None, None, None, None, None)

for idx_batch, data_batch in enumerate(data_loader):
    batch_labels, batch_pred_labels, batch_best_node_labels, batch_pred_best_node_labels, batch_is_correct_labels, batch_graph_size = \
            model(*data_batch, training=False)

    is_first = True if idx_batch == 0 else False
    labels = append_batch_results(labels, batch_labels, first=is_first)
    pred_labels = append_batch_results(pred_labels, batch_pred_labels, first=is_first)

    if args.task_level == 'node':
         best_node_labels = append_batch_results(best_node_labels, batch_best_node_labels, first=is_first)
         pred_best_node_labels = append_batch_results(pred_best_node_labels, batch_pred_best_node_labels, first=is_first)

         is_correct_labels = append_batch_results(is_correct_labels, batch_is_correct_labels, first=is_first)
    graph_size = append_batch_results(graph_size, batch_graph_size, first=is_first)

# saving output predictions
with open(args.output_file, 'w') as outf:

    if args.task_level == 'node':
        graph_cumsize = np.insert(np.cumsum(graph_size), 0, 0)
 
        for kdx in range(len(graph_size)):
            if kdx != 0:
                outf.write('\n')
            graph_pred_labels = tf.gather(pred_labels, tf.range(graph_cumsize[kdx], graph_cumsize[kdx+1]))
            graph_labels_i = tf.gather(labels, tf.range(graph_cumsize[kdx], graph_cumsize[kdx+1]))
 
            for jdx, pred_label in enumerate(graph_pred_labels):
                if dataset.node_labels is not None:
                    outf.write('%-8.5f %4i\n'%(pred_label, graph_labels_i[jdx]))
                else:
                    outf.write('%-8.5f\n'%label)

    elif args.task_level == 'graph':
        for jdx, pred_label in enumerate(pred_labels):
                if dataset.graph_labels is not None:
                    outf.write('%-8.5f %6.2f\n'%(pred_label, labels[jdx]))
                else:
                    outf.write('%-8.5f\n'%pred_label)

if args.task_level == 'node' and dataset.node_labels is not None:
    # printing success rate and loss if labels are provided
    success_rate = model.success_rate(best_node_labels, pred_best_node_labels, is_correct_labels)

    # call loss values
    loss_values = model.call_loss(labels, pred_labels)
    print(','.join(['%.5f'%value for value in {'success': success_rate, **loss_values}.values()])+'\n')

elif args.task_level == 'graph' and dataset.graph_labels is not None:
    pearson_coefficient = model.pearson(labels, pred_labels)
    r_squared_value = model.r_squared_value(labels, pred_labels)

    # call loss values
    loss_values = model.call_loss(labels, pred_labels)
    print(','.join(['%.5f'%value for value in {'pearson': pearson_coefficient, 'r2': r_squared_value, **loss_values}.values()]))

